# TODO: EDA и подготовка данных Lenta для Uplift Modeling

## Источник данных
- **Датасет:** Lenta (BigTarget Hackathon, Лента + Microsoft, лето 2020)
- **Загрузка:** `from sklift.datasets import fetch_lenta`
- **Тип задачи:** бинарная классификация (uplift)
- **Treatment:** маркетинговая коммуникация (рассылка)
- **Target:** визит в магазин / покупка (`response_att`)

---

## Этап 1. Загрузка и первичный осмотр

### 1.1. Загрузка данных
- [x] Установить зависимости: `scikit-uplift`, `pandas`, `numpy`, `matplotlib`, `seaborn`
- [x] Загрузить датасет через `fetch_lenta()`
- [x] Разделить на `data` (признаки), `target` (response_att), `treatment` (group)
- [x] Вывести `dataset.DESCR` — описание датасета
- [x] Вывести `dataset.feature_names` — список признаков

### 1.2. Размер и структура
- [x] `data.shape` — количество строк и столбцов
- [x] `data.dtypes` — типы всех признаков (определить: категориальные, числовые, бинарные)
- [x] `data.head(10)` — первые строки для визуального осмотра
- [x] `data.info()` — общая сводка (non-null counts, типы, потребление памяти)
- [x] `data.describe()` — базовая статистика числовых признаков (min, max, mean, std, квартили)
- [x] `data.describe(include='object')` — статистика категориальных признаков (unique, top, freq)
- [x] Вывести список всех столбцов с их типами в таблицу для отчёта

---

## Этап 2. Анализ целевой переменной и treatment

### 2.1. Распределение treatment (group)
- [x] `treatment.value_counts()` и `treatment.value_counts(normalize=True)` — абсолютные и относительные частоты
- [x] Визуализация: countplot / barplot для treatment
- [x] **Вывод:** test=515,892 (75.1%), control=171,137 (24.9%) — соотношение ~3:1

### 2.2. Распределение target (response_att)
- [x] `target.value_counts()` и `target.value_counts(normalize=True)`
- [x] Визуализация: countplot для target
- [x] **Вывод:** conversion rate = 10.82%, сильный дисбаланс классов (89.2% негативных)

### 2.3. Кросс-таблица treatment × target
- [x] `pd.crosstab(treatment, target)` — абсолютные значения
- [x] `pd.crosstab(treatment, target, normalize='index')` — пропорции (conversion rate по группам)
- [x] Вычислить **общий uplift** = conversion_rate(treatment=1) − conversion_rate(treatment=0)
- [x] Визуализация: сгруппированный barplot (conversion rate по treatment/control)
- [x] **Вывод:** uplift = +0.75 п.п. (CR treatment=11.01%, CR control=10.26%) — положительный эффект кампании

---

## Этап 3. Анализ признаков (Features)

### 3.1. Пропущенные значения
- [x] `data.isnull().sum()` — количество пропусков по каждому столбцу
- [x] `data.isnull().mean()` — доля пропусков по каждому столбцу
- [x] Визуализация: barplot долей пропусков (только столбцы с пропусками > 0)
- [x] Классифицировать: мало пропусков (<5%), умеренно (5–30%), много (>30%)
- [x] **Результат:** 153 из 193 столбцов имеют пропуски. 60 столбцов >30% (k_var_*, k_var_count_per_cheque_15d/1m), 53 умеренно (5–30%), 40 мало (<5%). Пропуски группируются по паттернам (одинаковое кол-во у связанных признаков).

### 3.2. Числовые признаки
Для каждого числового признака:
- [x] Описательная статистика: mean, median, std, min, max, квартили
- [x] Гистограмма распределения
- [x] Boxplot для обнаружения выбросов
- [x] Проверка на скошенность (skewness): `data[col].skew()`
- [x] Распределение **в разрезе treatment/control** — overlaid histograms или KDE
- [x] **Результат:** 156 из 192 числовых признаков сильно скошены (|s|>1), все purchase-related метрики имеют тяжёлые правые хвосты

Конкретные признаки для анализа (если присутствуют):
- [x] `age` — min=0 (1 случай), 330 значений <14, 129 значений >90; skewness=0.13 (симметричный)
- [x] Числовые метрики покупательского поведения — частота, суммы, давность

### 3.3. Категориальные признаки
Для каждого категориального признака:
- [x] `value_counts()` — частоты категорий
- [x] Barplot частот
- [x] Количество уникальных значений
- [x] Проверка на редкие категории (< 1% наблюдений)
- [x] Распределение **в разрезе treatment/control** — stacked barplot или grouped barplot

Конкретные признаки:
- [x] `gender` — Ж: 433k, М: 244k, «Не определен»: 1,090 (редкая категория <1%), пропуски: 8,581
- [x] `main_format` — 0 (суперстор) доминирует (~90%), 1 (продуктовый) ~10%

### 3.4. Константные и квазиконстантные признаки
- [x] Найти признаки с `nunique() == 1` (константные) → **нет таких**
- [x] Найти признаки где одно значение занимает > 99% → **нет таких**

### 3.5. Дубликаты
- [x] `data.duplicated().sum()` — 30 полных дубликатов строк
- [x] Проверка: вероятно разные клиенты с одинаковыми признаками, а не ошибки данных

---

## Этап 4. Проверка рандомизации (Balance Check)

> **Это критический этап для uplift modeling. Без него нельзя доверять результатам моделей.**

### 4.1. Сравнение средних (числовые признаки)
- [x] Для каждого числового признака: среднее в treatment vs среднее в control
- [x] t-test для каждого признака → 154/192 значимых (p<0.05), но только 1 с |SMD|>0.1
- [x] Таблица: признак | mean_treatment | mean_control | p-value | significant?
- [x] Визуализация: SMD (Standardized Mean Difference) plot

### 4.2. Сравнение распределений (категориальные признаки)
- [x] Для каждого категориального признака: пропорции категорий в treatment vs control
- [x] Chi-squared test: gender (p<0.001, значимо), main_format (p=0.0003, значимо)
- [x] Таблица: признак | chi2 | p-value | significant?

### 4.3. Propensity Score проверка
- [x] LightGBM для предсказания treatment по всем признакам
- [x] AUC-ROC = 0.5575 ± 0.0016 (пограничное значение)
- [x] Главные различающие признаки: response_viber, response_sms, months_from_register
- [x] Feature importance визуализация

### 4.4. Вывод по рандомизации
- [x] **Заключение:** рандомизация в целом приемлемая. AUC=0.5575 (пограничное). Много стат. значимых различий (154/192), но все из-за большой выборки (N=687k) — практически значимых (|SMD|>0.1) только 1. Основной дисбаланс в response_viber/sms (отклик на прошлые кампании). Propensity score weighting не обязателен, но стоит учитывать при интерпретации.

---

## Этап 5. Корреляционный анализ

### 5.1. Корреляция между признаками
- [x] Матрица корреляций для числовых признаков (Pearson)
- [x] Heatmap корреляционной матрицы
- [x] Выявить пары с |corr| > 0.8 (высокая мультиколлинеарность)
- [x] **Решение:** 125 пар с |corr|>0.8, 126 уникальных признаков. Топ по числу связей: sale_count/sum_6m_g33/g32/g57 (по 5 пар). Рекомендация: итеративно удалять признак с наибольшим числом связей из каждой пары.

### 5.2. Связь признаков с target
- [x] Корреляция каждого числового признака с target (point-biserial)
- [x] Conversion rate в разрезе категорий каждого категориального признака
- [x] **Результат:** Все 192 числовых признака значимо коррелируют с target (p<0.05). Топ-5: k_var_days_between_visits_15d (r=0.30), k_var_disc_per_cheque_15d (r=0.29), k_var_days_between_visits_1m (r=0.28), k_var_cheque_15d (r=0.27), stdev_discount_depth_15d (r=0.26). Gender: Ж CR=10.4%, М CR=11.2%. Main_format: 0 CR=10.3%, 1 CR=14.3%.

### 5.3. Взаимодействие признаков с treatment (uplift-специфичный анализ)
- [x] Для ключевых признаков: считать uplift **в разрезе значений признака**
  - gender: М uplift=+0.81 п.п., Ж uplift=+0.74 п.п., «Не определен» uplift=−2.03 п.п.
  - age: uplift растёт с возрастом — <25: +0.86 п.п., 65+: +1.21 п.п.
  - response_sms / response_viber: uplift зависит от истории откликов
- [x] Визуализация: barplot uplift по подгруппам (gender, main_format, age groups, key numeric features)
- [x] **Вывод:** потенциальные effect modifiers: age (монотонный рост uplift), gender, response_sms/viber. Эти признаки — первоочередные кандидаты для uplift-модели.

---

## Этап 6. Обработка данных для моделирования

### 6.1. Обработка пропусков
- [x] Для числовых: заполнение **медианой** для всех числовых признаков
- [x] Для категориальных: `gender` заполнен категорией `"Unknown"` (8,581 пропуск → 1.25%)
- [x] Для признаков с >10% пропусков: создано **102 флага `_missing`** (информативный сигнал: отсутствие покупок за период)
- [x] **Результат:** 0 пропусков после обработки

### 6.2. Кодирование категориальных признаков
- [x] `gender` (4 категории: Ж, М, Не определен, Unknown) → **LabelEncoder** (0=Unknown, 1=Ж, 2=М, 3=Не определен)
- [x] `main_format` уже числовой (0/1) → оставлен как есть
- [x] **Результат:** 0 object-столбцов, все числовые. OHE не применён — базовая модель tree-based.

### 6.3. Обработка выбросов
- [x] **Winsorization** (clipping по 1–99 перцентилю) для 171 сильно скошенного признака (|skew| > 1)
- [x] Строки не удалены — каждый клиент ценен для uplift

### 6.4. Удаление ненужных признаков
- [x] Константных/квазиконстантных: 0 (не было)
- [x] Высококоррелированных (|corr| > 0.8): удалено **51 признак** (итеративный алгоритм — удаляем признак с наибольшим числом связей)
- [x] Treatment, target, confounders сохранены
- [x] Пост-treatment признаков нет (все измерены до кампании, подтверждено по columns_description.md)

### 6.5. Масштабирование (опционально)
- [x] StandardScaler подготовлен (fit) для 140 непрерывных признаков, **не применён** (tree-based модели не требуют)
- [x] **Итог:** 687,029 строк × 244 признака (142 исходных + 102 _missing флагов)

---

## Этап 7. Формирование финального датасета

### 7.1. Train/Test Split
- [x] Stratified split по **treatment × target** (4 комбинации: test_0, test_1, control_0, control_1)
- [x] Пропорция: **70/30** → Train: 480,920 строк, Test: 206,109 строк
- [x] `random_state=42` для воспроизводимости
- [x] Проверка: treatment rate, conversion rate и uplift идентичны в train/test (стратификация корректна)

### 7.2. Сохранение
- [x] Сохранены: `X_train`, `X_test` (parquet), `y_train`, `y_test`, `treatment_train`, `treatment_test` (csv)
- [x] Формат: parquet для признаков (86 + 40 MB), csv для target/treatment
- [x] Pipeline: `preprocessing_pipeline.pkl` (LabelEncoder, медианы, scaler, списки удалённых/скошенных признаков)

### 7.3. Итоговая сводка
- [x] Train: 480,920 × 244, Test: 206,109 × 244 (142 исходных + 102 _missing)
- [x] Удалено 51 признак (высокая корреляция |r|>0.8)
- [x] Преобразования: пропуски → медиана + "Unknown", gender → LabelEncoder, winsorization 1-99%, _missing флаги

---

## Структура выходных файлов

```
project/
├── notebooks/
│   ├── 01_load_and_overview.ipynb      # Этапы 1–2
│   ├── 02_feature_analysis.ipynb       # Этапы 3–4
│   ├── 03_correlations_and_uplift.ipynb # Этап 5
│   └── 04_preprocessing.ipynb          # Этапы 6–7
├── data/
│   ├── raw/                            # Исходные данные
│   └── processed/                      # Обработанные train/test
├── src/
│   ├── data_loader.py                  # Загрузка и кэширование
│   └── preprocessing.py                # Pipeline предобработки
├── reports/
│   └── eda_summary.md                  # Итоговый отчёт EDA
└── todo.md                             # Этот файл
```

---

## Зависимости

```
scikit-uplift
pandas
numpy
matplotlib
seaborn
scipy          # для стат. тестов (t-test, chi-squared)
scikit-learn   # для train_test_split, propensity score модели, preprocessing
lightgbm       # для propensity score check и как base learner
catboost       # как base learner для uplift моделей
```
** use contex7 mcp to search documentation for the frameworks and libraries used**