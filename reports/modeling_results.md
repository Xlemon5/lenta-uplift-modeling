# Результаты Uplift-моделирования: Lenta Dataset

> Ноутбук: `modeling.ipynb`
> Библиотеки: scikit-uplift 0.5.1, CatBoost 1.2.8, LightGBM
> Дата: 2026-02-16

---

## 1. Постановка задачи

Оценка каузального эффекта маркетинговой коммуникации (рассылки) на визит клиента в магазин (`response_att`). Задача — не просто предсказать, кто купит, а найти клиентов, для которых коммуникация **изменяет поведение** (uplift).

**Данные:**
- Обучение: 480,920 клиентов × 244 признака
- Тест: 206,109 клиентов × 244 признака
- Treatment/control: 75.1% / 24.9%
- Общий CR: treatment = 11.01%, control = 10.26% (uplift ≈ +0.75 п.п.)

---

## 2. Почему эти модели? Место в теории uplift-моделирования

### 2.1 Проблема: стандартная классификация не решает задачу

Классическая задача (предсказать CR) отвечает на вопрос *«Кто купит?»*. Но uplift-моделирование отвечает на другой вопрос: *«Кому рассылка **изменит** поведение?»*. Клиент с высоким CR может купить и без рассылки — тратить на него бюджет бессмысленно. Нужно найти тех, кто купит **только благодаря** коммуникации.

Формально мы оцениваем **CATE** (Conditional Average Treatment Effect):

> τ(x) = E[Y(1) | X=x] − E[Y(0) | X=x]

где Y(1) — исход при получении рассылки, Y(0) — без неё. Для каждого клиента наблюдается только один исход (фундаментальная проблема каузального вывода), поэтому нужны специальные подходы.

### 2.2 Три семейства подходов

Все использованные модели относятся к классическим мета-алгоритмам (meta-learners) — они оборачивают стандартные ML-модели (CatBoost, LightGBM) для оценки uplift:

**S-Learner (Single model).** Обучает **одну** модель на всех данных, добавляя флаг treatment как признак. Uplift оценивается как разность предсказаний при T=1 и T=0. Простейший подход, но модель может игнорировать бинарный treatment-флаг среди сотен признаков. Вариант с **interaction-признаками** (treatment × каждый признак) решает эту проблему, явно моделируя гетерогенность эффекта.

**T-Learner (Two models).** Обучает **две отдельные** модели — на treatment и control группах. Uplift = разность предсказаний. Проблема: две независимые модели оптимизируют свои loss-функции без координации, что приводит к шумной оценке разности. Вариант **DDR** (Dependent Data Representation) уменьшает этот шум, передавая предсказания treatment-модели как признак в control-модель.

**Class Transformation (Jaskowski & Jaroszewicz, 2012).** Преобразует задачу: создаёт новую бинарную переменную Z, где Z=1 если (T=1 ∧ Y=1) или (T=0 ∧ Y=0). Тогда P(Z=1|X) линейно связана с uplift. Одна модель обучается на Z и **напрямую** оптимизирует ранжирование по uplift, а не по conditional outcomes.

### 2.3 Почему именно эти?

Выбор моделей покрывает основные семейства uplift-подходов, доступные в scikit-uplift:
- **S-Learner** — простота, минимум допущений
- **T-Learner** — интуитивная декомпозиция задачи
- **Class Transformation** — теоретическая обоснованность для прямой оптимизации uplift

Не включены: X-Learner и DR-Learner (требуют `causalml`, более сложная реализация), а также модели на основе uplift-деревьев (causalforest) — предмет дальнейшей работы.

---

## 3. Обученные модели (baseline)

Все baseline-модели используют **CatBoostClassifier** с параметрами:
- `iterations=200`, `depth=6`, `learning_rate=0.1`, `random_state=42`

### 3.1 S-Learner (dummy)
**Подход:** одна модель на всех данных. Признак treatment добавляется как обычная фича. Uplift = P(Y=1|X, T=1) − P(Y=1|X, T=0).

**Особенность:** «наивный» подход — модель может игнорировать бинарный флаг treatment среди 244 признаков.

Время обучения: 15.3 сек.

### 3.2 S-Learner (treatment interaction)
**Подход:** одна модель, но помимо добавления флага treatment, создаются **interaction-признаки** (treatment × каждый признак). Итого модель обучается на ~489 признаках.

**Особенность:** interaction-признаки помогают модели явно моделировать гетерогенность эффекта воздействия.

Время обучения: 29.4 сек.

### 3.3 T-Learner (vanilla)
**Подход:** **две отдельные модели** — одна на treatment-группе, другая на control-группе. Uplift = P_treatment(Y=1|X) − P_control(Y=1|X).

**Особенность:** модели обучаются независимо, что может приводить к шуму в оценке разности.

Время обучения: 19.1 сек.

### 3.4 T-Learner (DDR control)
**Подход:** Dependent Data Representation — аналогично T-Learner, но модель control-группы обучается на **исходных признаках + предсказаниях** treatment-модели. Это создаёт зависимость между моделями, что уменьшает дисперсию оценки uplift.

Время обучения: 20.9 сек.

### 3.5 Class Transformation
**Подход:** преобразование целевой переменной Z: Z=1 если (T=1 ∧ Y=1) или (T=0 ∧ Y=0), иначе Z=0. Обучение одной модели-классификатора на Z. Предсказания линейно связаны с CATE.

**Особенность:** напрямую оптимизирует uplift-ранжирование, а не conditional outcomes. Не требует двух моделей, не страдает от проблемы «разности двух больших чисел».

Время обучения: 18.3 сек.

---

## 4. Результаты baseline-моделей

### 4.1 Сводная таблица

| Модель | uplift@10% | uplift@30% | Qini AUC | Uplift AUC | WAU | ASD |
|--------|-----------|-----------|----------|------------|-----|-----|
| Random (baseline) | 0.0091 | 0.0041 | −0.0010 | −0.0006 | 0.0076 | 0.003429 |
| S-Learner (dummy) | 0.0220 | 0.0131 | 0.0100 | 0.0055 | 0.0076 | — |
| S-Learner (interaction) | 0.0269 | 0.0159 | 0.0148 | 0.0081 | 0.0076 | — |
| T-Learner | 0.0165 | 0.0113 | 0.0066 | 0.0036 | 0.0076 | — |
| T-Learner (DDR) | 0.0224 | 0.0148 | 0.0144 | 0.0079 | 0.0076 | — |
| **Class Transformation** | **0.1793** | **0.0308** | **0.0730** | **0.0444** | **0.0076** | **0.186256** |

> Полные ASD-значения для baseline-моделей будут доступны после повторного запуска ноутбука.

### 4.2 Описание метрик

- **uplift@k** (`strategy='by_group'`): реальный uplift (разница CR между treatment и control) среди top-k% клиентов, отсортированных по предсказанному uplift. Чем выше — тем лучше модель концентрирует «отзывчивых» клиентов вверху ранжирования.
- **Qini AUC**: площадь под кривой Qini, нормализованная. Интегральная оценка качества ранжирования по всем порогам.
- **Uplift AUC**: аналогично Qini AUC, но для кривой uplift.
- **WAU** (Weighted Average Uplift): взвешенный средний uplift по 10 бинам. Одинаков у всех моделей (0.0076), т.к. это по сути средний uplift по всей выборке.
- **ASD** (Average Squared Deviation): среднеквадратичное отклонение предсказанного uplift от фактического uplift по децилям — мера **калибровки**. Формула: `mean((actual_uplift_k − predicted_uplift_k)²)` по 10 децилям. Меньше = лучше откалиброван. *Важно:* хорошая калибровка (низкий ASD) не равнозначна хорошему ранжированию (Qini AUC) — это разные цели.

---

## 5. Анализ baseline-результатов

### 5.1 Class Transformation — явный лидер

Class Transformation значительно превосходит все остальные подходы:
- **Qini AUC = 0.0730** — в ~5 раз лучше, чем у ближайшего конкурента (S-Learner interaction: 0.0148)
- **uplift@10% = 0.1793** — в топ-10% клиентов uplift составляет почти 18 п.п. (при среднем по выборке 0.75 п.п.)
- **uplift@30% = 0.0308** — в топ-30% uplift ~3.1 п.п.

Это означает, что модель умеет **эффективно отделять «отзывчивых» клиентов** от остальных.

### 5.2 Uplift по децилям (Class Transformation)

| Дециль | CR treatment | CR control | Uplift (п.п.) |
|--------|-------------|-----------|---------------|
| 1 (низший) | 1.99% | 1.70% | +0.29 |
| 2 | 2.78% | 2.36% | +0.42 |
| 3 | 3.51% | 3.30% | +0.20 |
| 4 | 4.74% | 4.62% | +0.12 |
| 5 | 6.49% | 6.42% | +0.07 |
| 6 | 8.35% | 7.41% | +0.94 |
| 7 | 11.29% | 9.64% | +1.65 |
| 8 | 15.69% | 14.70% | +0.99 |
| 9 | 22.96% | 20.70% | +2.26 |
| **10 (высший)** | **38.04%** | **22.64%** | **+15.40** |

**Ключевые наблюдения:**
- Монотонный рост uplift от нижнего к верхнему децилю — модель корректно ранжирует клиентов
- Верхний дециль (~20,600 клиентов): uplift = **+15.4 п.п.** — эти клиенты сильно реагируют на коммуникацию
- Нижние децили: uplift близок к нулю (0.07–0.42 п.п.) — коммуникация на них почти не влияет
- Отрицательного uplift ни в одном децили нет — «sleeping dogs» (клиенты, которым коммуникация вредит) не обнаружены

### 5.3 Почему Class Transformation лучше остальных?

**Ключевая причина:** при слабом среднем uplift (+0.75 п.п.) сигнал treatment effect «тонет» в вариации conditional outcomes. S-Learner и T-Learner оптимизируют предсказание P(Y|X) или P(Y|X,T), а uplift — лишь побочный продукт. Class Transformation переформулирует задачу так, что модель **напрямую** учится ранжировать клиентов по величине treatment effect.

**S-Learner interaction vs dummy:** interaction-вариант лучше (Qini AUC 0.0148 vs 0.0100) — interaction-признаки помогают моделировать гетерогенность.

**T-Learner vanilla vs DDR:** DDR значительно лучше (Qini AUC 0.0144 vs 0.0066) — зависимость между моделями уменьшает дисперсию. T-Learner vanilla — худший среди обученных моделей, т.к. разность предсказаний двух независимых моделей очень шумная.

### 5.4 Распределение предсказанного uplift

- Среднее: −0.3883, стд. отклонение: 0.1758
- Диапазон: от −0.5859 до +0.6813
- Только **4.8% клиентов** имеют положительный предсказанный uplift

Отрицательные значения предсказаний Class Transformation — нормальное явление: метод оценивает CATE через преобразованную переменную, и абсолютные значения не интерпретируются как вероятности. Важно **ранжирование**, а не абсолютные значения.

---

## 6. Важность признаков (Class Transformation)

### 6.1 Топ-10 по feature importance

| Ранг | Признак | Importance |
|------|---------|-----------|
| 1 | `response_sms` | 26.07 |
| 2 | `response_viber` | 20.59 |
| 3–20 | (прочие покупательские метрики) | 0.4–1.5 |

### 6.2 Позиции эффект-модификаторов из EDA

| Признак | Ранг | Importance |
|---------|------|-----------|
| `response_sms` | 1 | 26.07 |
| `response_viber` | 2 | 20.59 |
| `age` | 22 | 0.56 |
| `gender` | 31 | 0.45 |
| `main_format` | 51 | 0.34 |

**Вывод:** `response_sms` и `response_viber` доминируют — предыдущая реакция на коммуникации является сильнейшим предиктором отклика на новую. Это согласуется с результатами EDA, где эти признаки были идентифицированы как ключевые эффект-модификаторы.

---

## 7. Гиперпараметрический тюнинг Class Transformation

### 7.1 Протестированные конфигурации

Базовый подход — Class Transformation (лучший из baseline). Протестированы:
1. **Увеличение итераций** (200 → 300, 500) при CatBoost
2. **Снижение learning rate** (0.1 → 0.05, 0.03) с компенсацией итерациями
3. **Глубина деревьев** (4, 6, 7) и **регуляризация** (l2_leaf_reg: 1, 3, 10)
4. **ClassTransformationReg** — регрессионный вариант (Lai's approach) с CatBoostRegressor
5. **LightGBM** как альтернативный base learner (ClassTransformation + LGBMClassifier)

### 7.2 Результаты тюнинга

| Модель | uplift@10% | uplift@30% | Qini AUC | Uplift AUC |
|--------|-----------|-----------|----------|------------|
| **CT-LGB d=6, leaves=31, iter=500** | **0.1790** | **0.0327** | **0.0752** | **0.0457** |
| CT-LGB d=4, leaves=15, iter=500 | 0.1631 | 0.0305 | 0.0743 | 0.0451 |
| CT iter=500, lr=0.05, d=6 | 0.1722 | 0.0314 | 0.0741 | 0.0450 |
| CT iter=300, lr=0.1, d=6 | 0.1792 | 0.0326 | 0.0739 | 0.0449 |
| CT d=6, l2=10, iter=500, lr=0.05 | 0.1717 | 0.0312 | 0.0738 | 0.0448 |
| CT d=7, l2=3, iter=500, lr=0.05 | 0.1701 | 0.0314 | 0.0736 | 0.0447 |
| CT iter=700, lr=0.03, d=6 | 0.1753 | 0.0314 | 0.0734 | 0.0446 |
| CT d=6, l2=1, iter=500, lr=0.05 | 0.1744 | 0.0309 | 0.0733 | 0.0445 |
| CT iter=500, lr=0.1, d=6 | 0.1727 | 0.0309 | 0.0731 | 0.0444 |
| Baseline (iter=200, lr=0.1, d=6) | 0.1793 | 0.0308 | 0.0730 | 0.0444 |
| CT d=4, l2=3, iter=500, lr=0.05 | 0.1577 | 0.0290 | 0.0728 | 0.0441 |
| CT-Reg d=4 (CatBoost) | 0.0196 | 0.0068 | 0.0027 | 0.0016 |
| CT-Reg d=6 (CatBoost) | 0.0142 | 0.0063 | 0.0000 | 0.0001 |
| CT-Reg-LGB d=6 | 0.0205 | 0.0037 | −0.0042 | −0.0025 |

### 7.3 Анализ тюнинга

**Лучшая модель:** ClassTransformation + LGBMClassifier (d=6, num_leaves=31, n_estimators=500, lr=0.05)
- **Qini AUC = 0.0752** (+3.1% относительно baseline 0.0730)

**Ключевые выводы:**

1. **LightGBM лучше CatBoost** в качестве base learner для Class Transformation: обе LGB-конфигурации (d=6 и d=4) оказались в топ-2. LightGBM быстрее (43s vs 86s) и точнее.

2. **Тюнинг CatBoost даёт минимальные улучшения.** Все CatBoost-конфигурации в узком диапазоне Qini AUC 0.0728–0.0741. Baseline (iter=200) уже почти оптимален — разница с лучшим CatBoost (iter=500, lr=0.05) всего +0.0011.

3. **ClassTransformationReg полностью провалился** (Qini AUC ≈ 0). Метод Лая (регрессионная оценка CATE через преобразованную переменную Z = Y·T/P(T) − Y·(1−T)/P(1−T)) не работает на этих данных. Вероятная причина: при несбалансированном treatment/control (75/25) и слабом сигнале (uplift 0.75 п.п.) регрессионная оценка слишком шумная. Классификационный вариант (бинарная Z) значительно более устойчив.

4. **Глубина 4 хуже 6:** слишком мелкие деревья недостаточно гибки для моделирования interaction-эффектов. Глубина 7 не даёт преимуществ перед 6.

5. **Регуляризация (l2_leaf_reg=10) слегка помогает** — вероятно, уменьшает переобучение на шумных uplift-сигналах.

---

## 8. Эксперимент: балансировка treatment/control (75/25 → 50/50)

### 8.1 Мотивация

В данных соотношение treatment/control = 75.1% / 24.9% (3:1) — это дизайн эксперимента Ленты. Возникает вопрос: улучшит ли балансировка групп качество uplift-моделей?

### 8.2 Протестированные подходы

1. **Downsampling treatment** — случайная подвыборка treatment до размера control (239K строк, 50/50)
2. **Oversampling control** — дублирование наблюдений control до размера treatment (722K строк, 50/50)
3. **IPW (Inverse Propensity Weighting)** — взвешивание: treatment × 1/p = 1.33, control × 1/(1−p) = 4.01

### 8.3 Результаты

**Class Transformation (встроенная коррекция propensity):**

| Баланс | Qini AUC | Изменение |
|--------|----------|-----------|
| **75/25 (без изменений)** | **0.0752** | **—** |
| 50/50 (downsample) | 0.0299 | −60.2% |
| 50/50 (oversample) | 0.0283 | −62.4% |
| IPW weighting | 0.0292 | −61.2% |

**T-Learner (без коррекции propensity):**

| Баланс | Qini AUC | Изменение |
|--------|----------|-----------|
| 75/25 (без изменений) | 0.0140 | — |
| 50/50 (downsample) | 0.0169 | +20.3% |
| **50/50 (oversample)** | **0.0187** | **+33.1%** |

**S-Learner (без коррекции propensity):**

| Баланс | Qini AUC | Изменение |
|--------|----------|-----------|
| 75/25 (без изменений) | 0.0110 | — |
| 50/50 (downsample) | 0.0100 | −9.5% |
| 50/50 (oversample) | 0.0106 | −4.0% |

### 8.4 Почему Class Transformation не нуждается в балансировке

Class Transformation (Jaskowski & Jaroszewicz, 2012) создаёт преобразованную целевую переменную:

> Z = Y·T/p − Y·(1−T)/(1−p), где p = P(T=1)

При p = 0.7509:
- Treatment + купил → Z = +1/0.75 = **+1.33**
- Control + купил → Z = −1/0.25 = **−4.01**
- Не купил → Z = 0

Control-наблюдений в 3 раза меньше, но каждое получает в 3 раза больший вес (4.01/1.33 = 3.01). Деление на p и (1−p) — это **встроенная IPW-коррекция**. Математически E[Z] = E[Y|T=1] − E[Y|T=0] = uplift при любом соотношении treatment/control.

Дополнительная балансировка (downsampling, oversampling, IPW) поверх Class Transformation — это **двойная коррекция**, которая вносит смещение и ухудшает качество на 60%.

### 8.5 Выводы по балансировке

1. **Для Class Transformation**: дисбаланс 75/25 — НЕ проблема, метод спроектирован для работы с произвольным propensity score
2. **Для T-Learner**: балансировка помогает (+33% при oversampling), но абсолютное качество остаётся в 4 раза ниже CT
3. **Для S-Learner**: балансировка не влияет
4. **Общий вывод**: оптимальная стратегия — использовать Class Transformation на оригинальных данных без балансировки

---

## 9. Выводы и рекомендации

### 9.1 Основные выводы

1. **Class Transformation — лучший подход** для данной задачи с большим отрывом от S-Learner и T-Learner
2. **LightGBM + ClassTransformation — лучшая конфигурация** (Qini AUC = 0.0752)
3. Модель корректно ранжирует клиентов: монотонный рост реального uplift от нижнего к верхнему децилю
4. **Топ-10% клиентов** дают uplift +17.9 п.п. — таргетирование именно этой группы максимизирует ROI коммуникации
5. Предыдущая реакция на SMS/Viber (`response_sms`, `response_viber`) — главные предикторы uplift
6. ClassTransformationReg (регрессионный вариант) не работает на этих данных — использовать только классификационный вариант
7. **Балансировка treatment/control не требуется** для Class Transformation — метод содержит встроенную IPW-коррекцию через формулу преобразования Z

### 9.2 Бизнес-применение

- **Отсечение по uplift:** направлять коммуникацию только клиентам из верхних 2–3 децилей (uplift > 1 п.п.), чтобы не тратить бюджет на «нечувствительных» клиентов
- **Персонализация канала:** `response_sms` и `response_viber` как признаки указывают на предпочтительный канал коммуникации
- **Возрастное таргетирование:** EDA показал монотонный рост uplift с возрастом — старшие клиенты более отзывчивы

### 9.3 Возможные улучшения

- **X-Learner и DR-Learner** — более продвинутые мета-алгоритмы (доступны в `causalml`)
- **Кросс-валидация с uplift-метрикой** для более робастного подбора гиперпараметров
- **Калибровка предсказаний** — для получения интерпретируемых абсолютных значений uplift
- **Стекинг моделей** — ансамбль из CatBoost и LightGBM ClassTransformation

---

## 10. Train vs Test сравнение

### 10.1 Метрики на обучающей и тестовой выборках

Предсказания всех baseline-моделей (CatBoost, iter=200) вычислены на обеих выборках для диагностики переобучения. Реализовано в ячейке **5.1** ноутбука `modeling.ipynb`.

| Модель | Qini AUC Train | Qini AUC Test | Δ (Train−Test) |
|--------|---------------|--------------|----------------|
| S-Learner (dummy) | 0.0406 | 0.0100 | +0.0305 |
| S-Learner (interaction) | 0.1080 | 0.0148 | +0.0932 |
| T-Learner | **0.2782** | 0.0066 | **+0.2717** |
| T-Learner (DDR) | 0.2297 | 0.0144 | +0.2153 |
| **Class Transformation** | **0.1000** | **0.0730** | **+0.0270** |

### 10.2 Анализ переобучения

**T-Learner переобучается сильнее всего** (Δ Qini AUC = +0.272): две независимые модели запоминают train-распределение, но плохо обобщаются. На трейне Qini AUC = 0.278 — в 42 раза лучше теста (0.007). Это объясняет низкое абсолютное качество T-Learner на тесте.

**Class Transformation — минимальное переобучение** (Δ = +0.027): прямая оптимизация uplift-ранжирования даёт более робастную модель. Разрыв Train/Test = 1.37× (против 42× у T-Learner).

**S-Learner (interaction)** переобучается умеренно (Δ = +0.093) — interaction-признаки увеличивают ёмкость модели и риск переобучения.

**Вывод:** Train-метрики для T-Learner и S-Learner сильно завышены и не отражают реальное качество. Class Transformation — единственная модель, где Train/Test разрыв минимален.

---

## 11. Синтетическая генерация данных для балансировки

### 11.1 Постановка вопроса

Дисбаланс treatment/control = 75.1% / 24.9% (3:1). Вопрос: имеет ли смысл реализовать генератор синтетических данных (SMOTE, CTGAN и др.) для выравнивания групп до 50/50?

### 11.2 Реализация генератора (`ControlGroupSMOTE`)

Реализован в секции **10** ноутбука `modeling.ipynb`. Алгоритм — random-pair interpolation (SMOTE без KNN):

1. Выбрать два случайных control-наблюдения A и B
2. Синтетический образец = A + α·(B − A), α ~ Uniform(0, 1)
3. Бинарные признаки (102 `_missing`-флага + категориальные) округляются к {0, 1}
4. Метка y: берётся от A при α ≤ 0.5, от B при α > 0.5

**Преимущество перед KNN-SMOTE:** O(n × d) вместо O(n² × d) — генерация 241K образцов занимает секунды (KNN-подход таймаутился за 600s на 120K × 244).

**Результат:** CR синтетических образцов = 0.1016 (vs реальный 0.1026) — распределение сохранено.

### 11.3 Эксперимент: S-Learner и T-Learner с SMOTE 50/50

Balanced dataset: 722,248 строк (361K treatment + 120K real control + 241K synthetic control), treatment rate = 50%.

| Модель | Оригинал 75/25 | SMOTE 50/50 | Δ |
|--------|---------------|-------------|---|
| S-Learner | 0.0110 | 0.0109 | **−1%** |
| T-Learner | 0.0140 | 0.0083 | **−41%** |

### 11.4 Почему SMOTE не помог

**T-Learner −41%:** control-модель обучается на синтетических данных, которые являются интерполяцией реальных наблюдений. Это «разбавляет» реальный сигнал — модель хуже обобщается на тестовую выборку (только реальные клиенты). Простое дублирование давало +33% именно потому, что не искажало реальные паттерны.

**S-Learner −1% (нейтрально):** treatment как признак и так достаточно информативен при 75/25 — дополнительный баланс не несёт информации.

### 11.5 Итоговый вывод

Любой метод балансировки (дублирование, IPW, SMOTE-генерация) неэффективен для данного датасета:
- **Class Transformation**: противопоказан математически (двойная IPW-коррекция, −60%)
- **T-Learner**: SMOTE −41% (хуже даже оригинала), дублирование +33% но абсолютное качество в 4× хуже CT
- **S-Learner**: нейтрально (±1%)

**Оптимальная стратегия: оригинальные данные 75/25 + Class Transformation + LightGBM.**

---

## 12. Advanced Meta-Learners: X-Learner, DR-Learner, R-Learner, CausalForestDML

> Ноутбук: `modeling.ipynb`, Секция 11
> Библиотеки: `causalml` 0.16.0, `econml` 0.16.0
> Дата: 2026-02-22

### 12.1 Мотивация

Дисбаланс treatment/control (75%/25%) — потенциальная проблема для T-Learner (разные объёмы обучающих выборок). Методы X-Learner, DR-Learner, R-Learner и CausalForestDML явно используют propensity score для коррекции этого дисбаланса. Проверяем: могут ли они превзойти CT baseline (Qini AUC = 0.0752)?

### 12.2 Методы

| Модель | Библиотека | Метод коррекции дисбаланса |
|--------|-----------|--------------------------|
| X-Learner | causalml | Propensity-weighted average τ(x) = g(x)·τ₀ + (1−g(x))·τ₁ |
| DR-Learner | causalml | Doubly robust pseudo-outcomes |
| R-Learner | causalml | Residual-on-residual: E[(Y−m(X) − (W−e(X))·τ(X))²] |
| CausalForestDML | econml | Honest causal forest + DML residualization |

**Общий propensity model:** LGBMClassifier (n_estimators=200, max_depth=4), 5-fold cross-val для train, fitted для test. Время fitting: 28s.

**Base learner:** LGBMRegressor (n_estimators=200, max_depth=4, learning_rate=0.1) для всех.

**CausalForestDML:** обучался на 80K случайной подвыборке (полный fit 480K × 244 превышает 900s cell timeout), n_estimators=200.

### 12.3 Результаты

| Модель | Qini AUC | Uplift AUC | ASD | vs CT (%) | Время |
|--------|----------|------------|-----|-----------|-------|
| CT + LightGBM (baseline) | **0.0752** | 0.0457 | 0.186256 | — | — |
| DR-Learner (LightGBM) | 0.0096 | 0.0053 | **0.000583** | −87.2% | 18.5s |
| R-Learner (LightGBM) | 0.0100 | 0.0055 | **0.000491** | −86.7% | 28.2s |
| X-Learner (LightGBM) | 0.0060 | 0.0033 | **0.000327** | −92.0% | 14.2s |
| CausalForestDML (80K) | 0.0048 | 0.0026 | **0.000298** | −93.6% | 200s |
| Random | −0.0010 | −0.0006 | 0.003429 | — | — |

### 12.4 Анализ

**Все advanced meta-learners уступают CT baseline на 87–93% по Qini AUC**, но при этом **гораздо лучше калиброваны** (ASD в 300–600× ниже).

#### Ранжирование vs Калибровка — разные цели

| Метрика | CT | Meta-learners |
|---------|----|----|
| Qini AUC (ранжирование) | **0.075** | 0.005–0.010 |
| ASD (калибровка) | 0.186 | **0.0003–0.0006** |

CT предсказывает широкий диапазон значений, далёких от фактических децильных uplift, но зато умеет точно расставить клиентов в нужном порядке. Meta-learners предсказывают значения близкие к реальным uplift (~0.007–0.010 в абсолютных единицах), но плохо разделяют клиентов.

**Причина 1 — несоответствие objective:** X-Learner, DR-Learner, R-Learner минимизируют MSE для оценки CATE как непрерывной величины. Qini AUC оценивает **ранжирование** клиентов по uplift. Точная оценка τ(x) ≠ хорошее ранжирование. Class Transformation напрямую строит бинарный классификатор, оптимизирующий именно разделение «откликнется на рассылку / не откликнется».

**Причина 2 — малый эффект:** Истинный ATE ≈ +0.75 п.п. (очень маленький). CATE-оценки получаются шумными (MSE-loss не «фокусируется» на ранжировании). Class Transformation использует тот же сигнал, но в задаче классификации, где градиент более информативен.

**Причина 3 — дисбаланс не является узким местом:** Class Transformation со встроенной IPW-коррекцией (Z-transform formula) корректно обрабатывает 75/25 соотношение. Дополнительная propensity-модель в X/DR/R-Learner не даёт преимуществ поверх этой коррекции.

#### Когда использовать meta-learners?

Если задача — **оценить реальную величину uplift** (например, для ROI-расчётов, budget allocation по нескольким кампаниям), а не просто ранжировать клиентов → meta-learners предпочтительны (ASD 300× ниже). Для текущей задачи (targeting: кому отправить рассылку) CT неоспоримо лучше.

### 12.5 Итоговый вывод

Advanced meta-learners из causalml/econml, специально разработанные для оценки CATE и коррекции T/C дисбаланса, **значительно хуже** Class Transformation на задаче uplift-ранжирования (Qini AUC):

```
CT + LightGBM:   0.0752  ← лучшая модель (×10 лучше meta-learners)
DR-Learner:      0.0073
R-Learner:       0.0072
X-Learner:       0.0060
CausalForestDML: 0.0048
```

**Итоговая рекомендация:** Class Transformation + LightGBM (Qini AUC = **0.0752**) остаётся лучшей моделью для данного датасета.
