# Результаты Uplift-моделирования: Lenta Dataset

> Ноутбук: `modeling.ipynb`
> Библиотеки: scikit-uplift 0.5.1, CatBoost 1.2.8, LightGBM
> Дата: 2026-02-16

---

## 1. Постановка задачи

Оценка каузального эффекта маркетинговой коммуникации (рассылки) на визит клиента в магазин (`response_att`). Задача — не просто предсказать, кто купит, а найти клиентов, для которых коммуникация **изменяет поведение** (uplift).

**Данные:**
- Обучение: 480,920 клиентов × 244 признака
- Тест: 206,109 клиентов × 244 признака
- Treatment/control: 75.1% / 24.9%
- Общий CR: treatment = 11.01%, control = 10.26% (uplift ≈ +0.75 п.п.)

---

## 2. Почему эти модели? Место в теории uplift-моделирования

### 2.1 Проблема: стандартная классификация не решает задачу

Классическая задача (предсказать CR) отвечает на вопрос *«Кто купит?»*. Но uplift-моделирование отвечает на другой вопрос: *«Кому рассылка **изменит** поведение?»*. Клиент с высоким CR может купить и без рассылки — тратить на него бюджет бессмысленно. Нужно найти тех, кто купит **только благодаря** коммуникации.

Формально мы оцениваем **CATE** (Conditional Average Treatment Effect):

> τ(x) = E[Y(1) | X=x] − E[Y(0) | X=x]

где Y(1) — исход при получении рассылки, Y(0) — без неё. Для каждого клиента наблюдается только один исход (фундаментальная проблема каузального вывода), поэтому нужны специальные подходы.

### 2.2 Три семейства подходов

Все использованные модели относятся к классическим мета-алгоритмам (meta-learners) — они оборачивают стандартные ML-модели (CatBoost, LightGBM) для оценки uplift:

**S-Learner (Single model).** Обучает **одну** модель на всех данных, добавляя флаг treatment как признак. Uplift оценивается как разность предсказаний при T=1 и T=0. Простейший подход, но модель может игнорировать бинарный treatment-флаг среди сотен признаков. Вариант с **interaction-признаками** (treatment × каждый признак) решает эту проблему, явно моделируя гетерогенность эффекта.

**T-Learner (Two models).** Обучает **две отдельные** модели — на treatment и control группах. Uplift = разность предсказаний. Проблема: две независимые модели оптимизируют свои loss-функции без координации, что приводит к шумной оценке разности. Вариант **DDR** (Dependent Data Representation) уменьшает этот шум, передавая предсказания treatment-модели как признак в control-модель.

**Class Transformation (Jaskowski & Jaroszewicz, 2012).** Преобразует задачу: создаёт новую бинарную переменную Z, где Z=1 если (T=1 ∧ Y=1) или (T=0 ∧ Y=0). Тогда P(Z=1|X) линейно связана с uplift. Одна модель обучается на Z и **напрямую** оптимизирует ранжирование по uplift, а не по conditional outcomes.

### 2.3 Почему именно эти?

Выбор моделей покрывает основные семейства uplift-подходов, доступные в scikit-uplift:
- **S-Learner** — простота, минимум допущений
- **T-Learner** — интуитивная декомпозиция задачи
- **Class Transformation** — теоретическая обоснованность для прямой оптимизации uplift

Не включены: X-Learner и DR-Learner (требуют `causalml`, более сложная реализация), а также модели на основе uplift-деревьев (causalforest) — предмет дальнейшей работы.

---

## 3. Обученные модели (baseline)

Все baseline-модели используют **CatBoostClassifier** с параметрами:
- `iterations=200`, `depth=6`, `learning_rate=0.1`, `random_state=42`

### 3.1 S-Learner (dummy)
**Подход:** одна модель на всех данных. Признак treatment добавляется как обычная фича. Uplift = P(Y=1|X, T=1) − P(Y=1|X, T=0).

**Особенность:** «наивный» подход — модель может игнорировать бинарный флаг treatment среди 244 признаков.

Время обучения: 15.3 сек.

### 3.2 S-Learner (treatment interaction)
**Подход:** одна модель, но помимо добавления флага treatment, создаются **interaction-признаки** (treatment × каждый признак). Итого модель обучается на ~489 признаках.

**Особенность:** interaction-признаки помогают модели явно моделировать гетерогенность эффекта воздействия.

Время обучения: 29.4 сек.

### 3.3 T-Learner (vanilla)
**Подход:** **две отдельные модели** — одна на treatment-группе, другая на control-группе. Uplift = P_treatment(Y=1|X) − P_control(Y=1|X).

**Особенность:** модели обучаются независимо, что может приводить к шуму в оценке разности.

Время обучения: 19.1 сек.

### 3.4 T-Learner (DDR control)
**Подход:** Dependent Data Representation — аналогично T-Learner, но модель control-группы обучается на **исходных признаках + предсказаниях** treatment-модели. Это создаёт зависимость между моделями, что уменьшает дисперсию оценки uplift.

Время обучения: 20.9 сек.

### 3.5 Class Transformation
**Подход:** преобразование целевой переменной Z: Z=1 если (T=1 ∧ Y=1) или (T=0 ∧ Y=0), иначе Z=0. Обучение одной модели-классификатора на Z. Предсказания линейно связаны с CATE.

**Особенность:** напрямую оптимизирует uplift-ранжирование, а не conditional outcomes. Не требует двух моделей, не страдает от проблемы «разности двух больших чисел».

Время обучения: 18.3 сек.

---

## 4. Результаты baseline-моделей

### 4.1 Сводная таблица

| Модель | uplift@10% | uplift@30% | Qini AUC | Uplift AUC | WAU |
|--------|-----------|-----------|----------|------------|-----|
| Random (baseline) | 0.0091 | 0.0041 | −0.0010 | −0.0006 | 0.0076 |
| S-Learner (dummy) | 0.0220 | 0.0131 | 0.0100 | 0.0055 | 0.0076 |
| S-Learner (interaction) | 0.0269 | 0.0159 | 0.0148 | 0.0081 | 0.0076 |
| T-Learner | 0.0165 | 0.0113 | 0.0066 | 0.0036 | 0.0076 |
| T-Learner (DDR) | 0.0224 | 0.0148 | 0.0144 | 0.0079 | 0.0076 |
| **Class Transformation** | **0.1793** | **0.0308** | **0.0730** | **0.0444** | **0.0076** |

### 4.2 Описание метрик

- **uplift@k** (`strategy='by_group'`): реальный uplift (разница CR между treatment и control) среди top-k% клиентов, отсортированных по предсказанному uplift. Чем выше — тем лучше модель концентрирует «отзывчивых» клиентов вверху ранжирования.
- **Qini AUC**: площадь под кривой Qini, нормализованная. Интегральная оценка качества ранжирования по всем порогам.
- **Uplift AUC**: аналогично Qini AUC, но для кривой uplift.
- **WAU** (Weighted Average Uplift): взвешенный средний uplift по 10 бинам. Одинаков у всех моделей (0.0076), т.к. это по сути средний uplift по всей выборке.

---

## 5. Анализ baseline-результатов

### 5.1 Class Transformation — явный лидер

Class Transformation значительно превосходит все остальные подходы:
- **Qini AUC = 0.0730** — в ~5 раз лучше, чем у ближайшего конкурента (S-Learner interaction: 0.0148)
- **uplift@10% = 0.1793** — в топ-10% клиентов uplift составляет почти 18 п.п. (при среднем по выборке 0.75 п.п.)
- **uplift@30% = 0.0308** — в топ-30% uplift ~3.1 п.п.

Это означает, что модель умеет **эффективно отделять «отзывчивых» клиентов** от остальных.

### 5.2 Uplift по децилям (Class Transformation)

| Дециль | CR treatment | CR control | Uplift (п.п.) |
|--------|-------------|-----------|---------------|
| 1 (низший) | 1.99% | 1.70% | +0.29 |
| 2 | 2.78% | 2.36% | +0.42 |
| 3 | 3.51% | 3.30% | +0.20 |
| 4 | 4.74% | 4.62% | +0.12 |
| 5 | 6.49% | 6.42% | +0.07 |
| 6 | 8.35% | 7.41% | +0.94 |
| 7 | 11.29% | 9.64% | +1.65 |
| 8 | 15.69% | 14.70% | +0.99 |
| 9 | 22.96% | 20.70% | +2.26 |
| **10 (высший)** | **38.04%** | **22.64%** | **+15.40** |

**Ключевые наблюдения:**
- Монотонный рост uplift от нижнего к верхнему децилю — модель корректно ранжирует клиентов
- Верхний дециль (~20,600 клиентов): uplift = **+15.4 п.п.** — эти клиенты сильно реагируют на коммуникацию
- Нижние децили: uplift близок к нулю (0.07–0.42 п.п.) — коммуникация на них почти не влияет
- Отрицательного uplift ни в одном децили нет — «sleeping dogs» (клиенты, которым коммуникация вредит) не обнаружены

### 5.3 Почему Class Transformation лучше остальных?

**Ключевая причина:** при слабом среднем uplift (+0.75 п.п.) сигнал treatment effect «тонет» в вариации conditional outcomes. S-Learner и T-Learner оптимизируют предсказание P(Y|X) или P(Y|X,T), а uplift — лишь побочный продукт. Class Transformation переформулирует задачу так, что модель **напрямую** учится ранжировать клиентов по величине treatment effect.

**S-Learner interaction vs dummy:** interaction-вариант лучше (Qini AUC 0.0148 vs 0.0100) — interaction-признаки помогают моделировать гетерогенность.

**T-Learner vanilla vs DDR:** DDR значительно лучше (Qini AUC 0.0144 vs 0.0066) — зависимость между моделями уменьшает дисперсию. T-Learner vanilla — худший среди обученных моделей, т.к. разность предсказаний двух независимых моделей очень шумная.

### 5.4 Распределение предсказанного uplift

- Среднее: −0.3883, стд. отклонение: 0.1758
- Диапазон: от −0.5859 до +0.6813
- Только **4.8% клиентов** имеют положительный предсказанный uplift

Отрицательные значения предсказаний Class Transformation — нормальное явление: метод оценивает CATE через преобразованную переменную, и абсолютные значения не интерпретируются как вероятности. Важно **ранжирование**, а не абсолютные значения.

---

## 6. Важность признаков (Class Transformation)

### 6.1 Топ-10 по feature importance

| Ранг | Признак | Importance |
|------|---------|-----------|
| 1 | `response_sms` | 26.07 |
| 2 | `response_viber` | 20.59 |
| 3–20 | (прочие покупательские метрики) | 0.4–1.5 |

### 6.2 Позиции эффект-модификаторов из EDA

| Признак | Ранг | Importance |
|---------|------|-----------|
| `response_sms` | 1 | 26.07 |
| `response_viber` | 2 | 20.59 |
| `age` | 22 | 0.56 |
| `gender` | 31 | 0.45 |
| `main_format` | 51 | 0.34 |

**Вывод:** `response_sms` и `response_viber` доминируют — предыдущая реакция на коммуникации является сильнейшим предиктором отклика на новую. Это согласуется с результатами EDA, где эти признаки были идентифицированы как ключевые эффект-модификаторы.

---

## 7. Гиперпараметрический тюнинг Class Transformation

### 7.1 Протестированные конфигурации

Базовый подход — Class Transformation (лучший из baseline). Протестированы:
1. **Увеличение итераций** (200 → 300, 500) при CatBoost
2. **Снижение learning rate** (0.1 → 0.05, 0.03) с компенсацией итерациями
3. **Глубина деревьев** (4, 6, 7) и **регуляризация** (l2_leaf_reg: 1, 3, 10)
4. **ClassTransformationReg** — регрессионный вариант (Lai's approach) с CatBoostRegressor
5. **LightGBM** как альтернативный base learner (ClassTransformation + LGBMClassifier)

### 7.2 Результаты тюнинга

| Модель | uplift@10% | uplift@30% | Qini AUC | Uplift AUC |
|--------|-----------|-----------|----------|------------|
| **CT-LGB d=6, leaves=31, iter=500** | **0.1790** | **0.0327** | **0.0752** | **0.0457** |
| CT-LGB d=4, leaves=15, iter=500 | 0.1631 | 0.0305 | 0.0743 | 0.0451 |
| CT iter=500, lr=0.05, d=6 | 0.1722 | 0.0314 | 0.0741 | 0.0450 |
| CT iter=300, lr=0.1, d=6 | 0.1792 | 0.0326 | 0.0739 | 0.0449 |
| CT d=6, l2=10, iter=500, lr=0.05 | 0.1717 | 0.0312 | 0.0738 | 0.0448 |
| CT d=7, l2=3, iter=500, lr=0.05 | 0.1701 | 0.0314 | 0.0736 | 0.0447 |
| CT iter=700, lr=0.03, d=6 | 0.1753 | 0.0314 | 0.0734 | 0.0446 |
| CT d=6, l2=1, iter=500, lr=0.05 | 0.1744 | 0.0309 | 0.0733 | 0.0445 |
| CT iter=500, lr=0.1, d=6 | 0.1727 | 0.0309 | 0.0731 | 0.0444 |
| Baseline (iter=200, lr=0.1, d=6) | 0.1793 | 0.0308 | 0.0730 | 0.0444 |
| CT d=4, l2=3, iter=500, lr=0.05 | 0.1577 | 0.0290 | 0.0728 | 0.0441 |
| CT-Reg d=4 (CatBoost) | 0.0196 | 0.0068 | 0.0027 | 0.0016 |
| CT-Reg d=6 (CatBoost) | 0.0142 | 0.0063 | 0.0000 | 0.0001 |
| CT-Reg-LGB d=6 | 0.0205 | 0.0037 | −0.0042 | −0.0025 |

### 7.3 Анализ тюнинга

**Лучшая модель:** ClassTransformation + LGBMClassifier (d=6, num_leaves=31, n_estimators=500, lr=0.05)
- **Qini AUC = 0.0752** (+3.1% относительно baseline 0.0730)

**Ключевые выводы:**

1. **LightGBM лучше CatBoost** в качестве base learner для Class Transformation: обе LGB-конфигурации (d=6 и d=4) оказались в топ-2. LightGBM быстрее (43s vs 86s) и точнее.

2. **Тюнинг CatBoost даёт минимальные улучшения.** Все CatBoost-конфигурации в узком диапазоне Qini AUC 0.0728–0.0741. Baseline (iter=200) уже почти оптимален — разница с лучшим CatBoost (iter=500, lr=0.05) всего +0.0011.

3. **ClassTransformationReg полностью провалился** (Qini AUC ≈ 0). Метод Лая (регрессионная оценка CATE через преобразованную переменную Z = Y·T/P(T) − Y·(1−T)/P(1−T)) не работает на этих данных. Вероятная причина: при несбалансированном treatment/control (75/25) и слабом сигнале (uplift 0.75 п.п.) регрессионная оценка слишком шумная. Классификационный вариант (бинарная Z) значительно более устойчив.

4. **Глубина 4 хуже 6:** слишком мелкие деревья недостаточно гибки для моделирования interaction-эффектов. Глубина 7 не даёт преимуществ перед 6.

5. **Регуляризация (l2_leaf_reg=10) слегка помогает** — вероятно, уменьшает переобучение на шумных uplift-сигналах.

---

## 8. Выводы и рекомендации

### 8.1 Основные выводы

1. **Class Transformation — лучший подход** для данной задачи с большим отрывом от S-Learner и T-Learner
2. **LightGBM + ClassTransformation — лучшая конфигурация** (Qini AUC = 0.0752)
3. Модель корректно ранжирует клиентов: монотонный рост реального uplift от нижнего к верхнему децилю
4. **Топ-10% клиентов** дают uplift +17.9 п.п. — таргетирование именно этой группы максимизирует ROI коммуникации
5. Предыдущая реакция на SMS/Viber (`response_sms`, `response_viber`) — главные предикторы uplift
6. ClassTransformationReg (регрессионный вариант) не работает на этих данных — использовать только классификационный вариант

### 8.2 Бизнес-применение

- **Отсечение по uplift:** направлять коммуникацию только клиентам из верхних 2–3 децилей (uplift > 1 п.п.), чтобы не тратить бюджет на «нечувствительных» клиентов
- **Персонализация канала:** `response_sms` и `response_viber` как признаки указывают на предпочтительный канал коммуникации
- **Возрастное таргетирование:** EDA показал монотонный рост uplift с возрастом — старшие клиенты более отзывчивы

### 8.3 Возможные улучшения

- **X-Learner и DR-Learner** — более продвинутые мета-алгоритмы (доступны в `causalml`)
- **Кросс-валидация с uplift-метрикой** для более робастного подбора гиперпараметров
- **Калибровка предсказаний** — для получения интерпретируемых абсолютных значений uplift
- **Стекинг моделей** — ансамбль из CatBoost и LightGBM ClassTransformation
